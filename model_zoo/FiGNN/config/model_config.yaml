Base:
    model_root: './checkpoints/'
    num_workers: 3
    verbose: 1
    early_stop_patience: 5
    pickle_feature_encoder: True
    save_best_only: True
    eval_steps: null
    debug_mode: False
    group_id: null
    use_features: null
    feature_specs: null
    feature_config: null

FiGNN_new_amazon: # This is a config template
    model: FiGNN
    dataset_id: amazon_new
    loss: 'binary_crossentropy'
    metrics: ['logloss', 'AUC']
    task: binary_classification
    optimizer: adam
    learning_rate: 1.e-3
    embedding_regularizer: 0
    net_regularizer: 0
    batch_size: 1024
    embedding_dim: 16
    gnn_layers: 3
    use_residual: True
    use_gru: True
    reuse_graph_layer: False
    epochs: 100
    shuffle: False
    seed: 2000
    monitor: {'AUC': 1, 'logloss': -1}
    monitor_mode: 'max'

FiGNN_new_douban: # This is a config template
    model: FiGNN
    dataset_id: douban_new
    loss: 'binary_crossentropy'
    metrics: ['logloss', 'AUC']
    task: binary_classification
    optimizer: adam
    learning_rate: 1.e-3
    embedding_regularizer: 0
    net_regularizer: 0
    batch_size: 1024
    embedding_dim: 16
    gnn_layers: 3
    use_residual: True
    use_gru: True
    reuse_graph_layer: False
    epochs: 100
    shuffle: False
    seed: 2000
    monitor: {'AUC': 1, 'logloss': -1}
    monitor_mode: 'max'

FiGNN_new_ml10m: # This is a config template
    model: FiGNN
    dataset_id: ml10m_new
    loss: 'binary_crossentropy'
    metrics: ['logloss', 'AUC']
    task: binary_classification
    optimizer: adam
    learning_rate: 1.e-3
    embedding_regularizer: 0
    net_regularizer: 0
    batch_size: 1024
    embedding_dim: 16
    gnn_layers: 3
    use_residual: True
    use_gru: True
    reuse_graph_layer: False
    epochs: 100
    shuffle: False
    seed: 2000
    monitor: {'AUC': 1, 'logloss': -1}
    monitor_mode: 'max'

